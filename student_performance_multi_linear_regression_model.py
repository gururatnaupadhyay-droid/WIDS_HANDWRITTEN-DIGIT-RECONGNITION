# -*- coding: utf-8 -*-
"""Student_Performance Multi Linear Regression Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wJ4f9q3YtOPl06IwINqU6Hr4reoae6pX
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from google.colab import files
import math

df = pd.read_csv('Student_Performance.csv')
dataframe=df
# Encode categorical into a binary yes or no
df['Extracurricular Activities'] = df['Extracurricular Activities'].map({
    'Yes': 1,
    'No': 0
})


cols_to_scale = ['Hours Studied', 'Sleep Hours','Previous Scores','Sample Question Papers Practiced']

for x in cols_to_scale:
  df[x] = (df[x] - df[x].mean()) / df[x].std()      #Z Score Standardisation
test=df[8000::1]
df=df[:8000:1]
X = df.drop('Performance Index', axis=1).values     #training data
y = df['Performance Index'].values.reshape(-1, 1) # trianing answers   (Reshape y to be a column vector)

n_samples = X.shape[0]
X = np.c_[np.ones((n_samples, 1)), X]
'''
cols=[]
for i in range (6):
  a=0
  for b in range (8000):
    a+=X[b][i]**2
  cols.append(a)

cols=np.array(cols)
cols=cols.reshape(-1,1)
'''

n_features = X.shape[1]
beta = np.zeros((n_features, 1))
def gradient_descent(X, y, beta, lr=0.01, epochs=1000):
    n = len(y)
    losses = []

    for a in range(epochs):
        y_pred = X @ beta
        error = y_pred - y

        gradient = (2/n) * (X.T @ error)
        beta -= lr * gradient

        loss = np.mean(error ** 2)
        losses.append(loss)

    return beta, losses

b, losses = gradient_descent(X, y, beta, lr=0.01, epochs=900)

beta=b
beta2 = np.linalg.inv(X.T @ X) @ X.T @ y
output=np.c_[y,X@beta,X@beta2]
np.savetxt('output_file.csv',output, delimiter=',')


def evaluate_model(y_actual, y_pred):
    mse = np.mean((y_actual - y_pred)**2)
    ss_res = np.sum((y_actual - y_pred)**2)
    ss_tot = np.sum((y_actual - np.mean(y_actual))**2)
    r2 = 1 - ss_res/ss_tot
    return mse, r2

y_actual = y # Use the original y values
y_pred = X @ b # Calculate predictions using the final beta
mse, r2 = evaluate_model(y, X@beta)
mse2,r22=evaluate_model(y, X@beta2)
print(1-mse2/mse)
print (r2<r22)
print(cols)
print(output)

ye=test['Performance Index'].values.reshape(-1, 1)      #training answers
te=test.drop('Performance Index', axis=1).values    #testing data
te=np.c_[np.ones((len(te), 1)), te]
exp=te@beta
d=abs(exp-ye)/ye
print(d.mean())

exp2=te@beta2
d2=abs(exp2-ye)/ye
print(d2.mean())

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

model = LinearRegression()
model.fit(X, y)

y_pred_sklearn = model.predict(te)

mse_sklearn = mean_squared_error(ye, y_pred_sklearn)
r2_sklearn  = r2_score(ye, y_pred_sklearn)

print(mse_sklearn,mse)
print(r2_sklearn,r2)